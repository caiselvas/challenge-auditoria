{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (233, 6)\n",
      "Shape of validation data: (59, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "dataorig = pd.read_excel(\"C:/Users/Usuario/Documents/Projectes/ChallengeAuditoria/challenge-auditoria/data/inventory_data_month_index.xlsx\")\n",
    "\n",
    "dataorig[\"cost_valor\"] = dataorig[\"preu_venda_unitari_2023\"] / dataorig[\"cost_unitari_stock_2023\"]\n",
    "\n",
    "dataorig[\"proporcio_vendes_stock\"] = dataorig[\"vendes_2023\"] / dataorig[\"stock_final_2023\"]\n",
    "# Drop rows with missing values\n",
    "\n",
    "data = dataorig.copy()\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Encode categorical variables if needed\n",
    "# (If there are any categorical variables that need encoding)\n",
    "\n",
    "# Select relevant features for the Autoencoder\n",
    "features = [ 'proporcio_variacio_preu_venda_unitari_2022_2023', 'diferencia_entrada_sortida', 'dies_ultima_sortida', 'proporcio_vendes_stock', 'cost_valor', \"forecast_index\"]\n",
    "\n",
    "X = data[features]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of validation data:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.9730 - val_loss: 0.9218\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1410 - val_loss: 0.9021\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9454 - val_loss: 0.8674\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0300 - val_loss: 0.8194\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8876 - val_loss: 0.7614\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.7764 - val_loss: 0.7103\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7011 - val_loss: 0.6684\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7357 - val_loss: 0.6320\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5614 - val_loss: 0.6002\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5653 - val_loss: 0.5776\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5194 - val_loss: 0.5678\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4729 - val_loss: 0.5587\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4932 - val_loss: 0.5364\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4291 - val_loss: 0.5083\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4730 - val_loss: 0.4737\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4370 - val_loss: 0.4385\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3548 - val_loss: 0.4115\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2989 - val_loss: 0.3963\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3200 - val_loss: 0.3854\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2854 - val_loss: 0.3712\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2663 - val_loss: 0.3549\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3278 - val_loss: 0.3423\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2766 - val_loss: 0.3414\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2917 - val_loss: 0.3286\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2443 - val_loss: 0.3267\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2834 - val_loss: 0.3216\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2735 - val_loss: 0.3164\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2493 - val_loss: 0.3172\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2568 - val_loss: 0.3067\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2412 - val_loss: 0.3092\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2298 - val_loss: 0.3058\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2602 - val_loss: 0.3029\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2371 - val_loss: 0.3065\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2567 - val_loss: 0.3027\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2212 - val_loss: 0.3045\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2256 - val_loss: 0.3018\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2223 - val_loss: 0.2985\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2217 - val_loss: 0.3019\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2333 - val_loss: 0.2992\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2334 - val_loss: 0.2998\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2413 - val_loss: 0.2985\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2280 - val_loss: 0.2959\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2560 - val_loss: 0.2964\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2493 - val_loss: 0.2983\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2384 - val_loss: 0.2937\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2280 - val_loss: 0.2955\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2377 - val_loss: 0.2966\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2365 - val_loss: 0.2970\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2154 - val_loss: 0.2950\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2520 - val_loss: 0.2959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16706057710>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define Autoencoder architecture\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 4  # Increase the size of the encoding layer\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(128, activation='relu')(input_layer)  # Add more neurons\n",
    "encoder = Dense(encoding_dim, activation='relu')(encoder)\n",
    "decoder = Dense(128, activation='relu')(encoder)  # Add more neurons\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "\n",
    "autoencoder = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the Autoencoder model\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Assets needing depreciation:\n",
      "    Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   material  unitats_2022  \\\n",
      "38            38            38          38  133200405      376250.0   \n",
      "57            57            57          57  135061014      425000.0   \n",
      "\n",
      "    vendes_2022  preu_venda_unitari_2022  unitats_2023  vendes_2023  \\\n",
      "38     23075.96                 0.061331      132000.0      8650.32   \n",
      "57     39559.85                 0.093082      357000.0     34693.77   \n",
      "\n",
      "    preu_venda_unitari_2023  ...     Sep_2023     Oct_2022     Oct_2023  \\\n",
      "38                 0.065533  ...     0.000000  1372.369316     0.000000   \n",
      "57                 0.097181  ...  4252.638944   326.701890  6157.832593   \n",
      "\n",
      "      Nov_2022     Nov_2023     Dec_2022     Dec_2023  forecast_index  \\\n",
      "38  5054.69849     0.000000  4506.108044     0.000000        0.391960   \n",
      "57  3340.24985  5012.315323  4232.356450  2704.797758        0.228659   \n",
      "\n",
      "    cost_valor  proporcio_vendes_stock  \n",
      "38    1.597775                 0.72086  \n",
      "57    1.104251                 0.68027  \n",
      "\n",
      "[2 rows x 47 columns]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming reconstructions and X_val are numpy arrays\n",
    "reconstructions = autoencoder.predict(X_val)\n",
    "mse = tf.keras.losses.mean_squared_error(X_val, reconstructions)\n",
    "\n",
    "# Calculate reconstruction errors (no need to specify axis for 1D array)\n",
    "mse_numpy = mse.numpy()\n",
    "reconstruction_errors = mse_numpy\n",
    "\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = reconstruction_errors.mean() + 2 * reconstruction_errors.std()\n",
    "\n",
    "# Identify assets with reconstruction errors above the threshold\n",
    "anomalies_indices = [i for i, error in enumerate(reconstruction_errors) if error > threshold]\n",
    "anomalies = data.iloc[anomalies_indices]\n",
    "\n",
    "print(\"Assets needing depreciation:\")\n",
    "print(anomalies)\n",
    "print(len(anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets needing depreciation beyond acceptable range:\n",
      "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0   material  unitats_2022  \\\n",
      "1               1             1           1  115030252       75900.0   \n",
      "28             28            28          28  133066532           NaN   \n",
      "35             35            35          35  133100502      240000.0   \n",
      "146           146           146         146  152270347           NaN   \n",
      "197           197           197         197  153010114      723800.0   \n",
      "198           198           198         198  153010115     7937600.0   \n",
      "209           209           209         209  153110150    35825400.0   \n",
      "210           210           210         210  153110151     2906800.0   \n",
      "212           212           212         212  153110155     2756000.0   \n",
      "213           213           213         213  153110157     7384000.0   \n",
      "352           352           352         352  173430205    11835000.0   \n",
      "363           363           363         363  182040131      332800.0   \n",
      "\n",
      "     vendes_2022  preu_venda_unitari_2022  unitats_2023  vendes_2023  \\\n",
      "1        6825.62                 0.089929       27600.0      2127.68   \n",
      "28           NaN                      NaN       36000.0      1041.48   \n",
      "35      13191.12                 0.054963       60000.0      3084.00   \n",
      "146          NaN                      NaN     4960000.0     63988.00   \n",
      "197     24060.01                 0.033241      745800.0     22081.00   \n",
      "198    320326.09                 0.040356     4294400.0    132208.62   \n",
      "209    812679.69                 0.022684    34418800.0    669179.16   \n",
      "210     63774.72                 0.021940     1612000.0     29900.00   \n",
      "212     58779.76                 0.021328      988000.0     18048.16   \n",
      "213    168335.44                 0.022797     3744000.0     71062.16   \n",
      "352    413846.10                 0.034968     5378400.0    204323.56   \n",
      "363      8366.59                 0.025140      524800.0     12416.89   \n",
      "\n",
      "     preu_venda_unitari_2023  ...       Sep_2023      Oct_2022      Oct_2023  \\\n",
      "1                   0.077090  ...       0.000000   1047.632346    427.803972   \n",
      "28                  0.028930  ...     268.964901      0.000000    113.667525   \n",
      "35                  0.051400  ...       0.000000      0.000000      0.000000   \n",
      "146                 0.012901  ...       0.000000      0.000000   5619.676044   \n",
      "197                 0.029607  ...    4120.033749   4661.606509      0.000000   \n",
      "198                 0.030786  ...   14121.071328  31538.344558  10731.938710   \n",
      "209                 0.019442  ...  105186.553437      0.000000  76655.983904   \n",
      "210                 0.018548  ...    4387.019120      0.000000      0.000000   \n",
      "212                 0.018267  ...    1849.625390      0.000000   1723.825929   \n",
      "213                 0.018980  ...    7377.449774   6193.596414   7006.786188   \n",
      "352                 0.037990  ...   18820.954601  62460.177424  23519.541740   \n",
      "363                 0.023660  ...    1669.213519   1286.738724   1134.366530   \n",
      "\n",
      "         Nov_2022      Nov_2023       Dec_2022     Dec_2023  forecast_index  \\\n",
      "1        0.000000    193.955142     287.229412   150.170606        0.480055   \n",
      "28       0.000000     58.017030       0.000000   158.984206        0.414558   \n",
      "35     210.268521      0.000000    2614.657309     0.000000        1.000000   \n",
      "146      0.000000   3986.397079       0.000000   266.412386        0.092572   \n",
      "197      0.000000   2758.299312      98.050512  3035.711276        0.212443   \n",
      "198  23408.300203   4434.289298   45210.698187  2195.074081        0.184343   \n",
      "209  84728.501775  56587.435250  135113.422995     0.000000        0.274445   \n",
      "210    810.243139   3479.088885    6052.415029  1231.448634        0.346308   \n",
      "212   2625.631609   4718.181691    4053.363608   960.191292        0.423763   \n",
      "213      0.000000   6865.353087    6545.127559  3447.691325        0.363982   \n",
      "352  46867.360821  24619.363804   22534.818105     0.000000        0.244801   \n",
      "363    397.553919    239.752764    1299.428046   982.137329        0.193102   \n",
      "\n",
      "     cost_valor  proporcio_vendes_stock  \n",
      "1      0.997702                0.092508  \n",
      "28     0.949632                0.028930  \n",
      "35     0.990223                0.051400  \n",
      "146    0.923465                0.159970  \n",
      "197    0.956921                0.250920  \n",
      "198    0.995032                0.500790  \n",
      "209    0.959164                0.230418  \n",
      "210    0.915066                0.287500  \n",
      "212    0.901203                0.223923  \n",
      "213    0.936373                0.136658  \n",
      "352    0.951108                0.252251  \n",
      "363    0.923861                0.485035  \n",
      "\n",
      "[12 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define accounting standards\n",
    "salvage_value = 0  # Assumption: Salvage value is 0 (can be adjusted)\n",
    "original_cost = dataorig['cost_unitari_stock_2023']  # Original cost of the asset\n",
    "\n",
    "# Calculate the depreciation expense using the straight-line method\n",
    "# We need to estimate the useful life or make an assumption\n",
    "# For demonstration, let's assume a useful life of 5 years\n",
    "useful_life_years = 5\n",
    "depreciation_expense = (original_cost - salvage_value) / useful_life_years\n",
    "\n",
    "# Define an acceptable range for depreciation value\n",
    "# We can use a percentage of the original cost or a fixed value\n",
    "# For demonstration, let's use a percentage (e.g., 10%) of the original cost\n",
    "acceptable_range_percentage = 0  # 10%\n",
    "acceptable_depreciation_range = original_cost * acceptable_range_percentage\n",
    "\n",
    "# Calculate the lower and upper bounds of the acceptable range\n",
    "lower_bound = original_cost - acceptable_depreciation_range\n",
    "upper_bound = original_cost + acceptable_depreciation_range\n",
    "\n",
    "# Determine assets that fall outside the acceptable range\n",
    "outside_acceptable_range = (dataorig['preu_venda_unitari_2023'] < lower_bound)\n",
    "assets_outside_range = dataorig[outside_acceptable_range]\n",
    "\n",
    "print(\"Assets needing depreciation beyond acceptable range:\")\n",
    "print(assets_outside_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create some fake data, of values that would need depreciation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = {'proporcio_variacio_preu_venda_unitari_2022_2023': [-0.5, -1],\n",
    "        'diferencia_entrada_sortida': [100, 30],\n",
    "        'dies_ultima_sortida': [300, 500],\n",
    "        'proporcio_vendes_stock' : [0.7, 3],\n",
    "        'cost_valor' : [0.8, 1.1],\n",
    "        'forecast_index' : [1, 0.9]}\n",
    "new_dataframe = pd.DataFrame(data_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "references = encoder_model.predict(new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 28 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000167045B0720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "embeddings = encoder_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304.5515\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "distances = np.linalg.norm(embeddings - reference, axis=1)\n",
    "\n",
    "print(max(distances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0.2                                                              308\n",
      "Unnamed: 0.1                                                              308\n",
      "Unnamed: 0                                                                308\n",
      "material                                                            173041357\n",
      "unitats_2022                                                         896000.0\n",
      "vendes_2022                                                            9290.4\n",
      "preu_venda_unitari_2022                                              0.010369\n",
      "unitats_2023                                                         168000.0\n",
      "vendes_2023                                                           1967.28\n",
      "preu_venda_unitari_2023                                               0.01171\n",
      "variacio_preu_venda_unitari_2022_2023                                0.001341\n",
      "proporcio_variacio_preu_venda_unitari_2022_2023                      0.129355\n",
      "data_darrera_entrada                               1970-01-01 01:00:44.510000\n",
      "dies_ultima_entrada                                                     781.0\n",
      "data_darrera_sortida                               1970-01-01 01:00:45.348000\n",
      "dies_ultima_sortida                                                     -57.0\n",
      "diferencia_entrada_sortida                                              838.0\n",
      "stock_final_2023                                                       952000\n",
      "valor_total_stock_2023                                                6321.28\n",
      "cost_unitari_stock_2023                                               0.00664\n",
      "Jan_2022                                                           840.735286\n",
      "Jan_2023                                                           180.723382\n",
      "Feb_2022                                                          1347.613259\n",
      "Feb_2023                                                           141.199582\n",
      "Mar_2022                                                           684.544035\n",
      "Mar_2023                                                            20.507716\n",
      "Apr_2022                                                            145.59652\n",
      "Apr_2023                                                           311.743148\n",
      "May_2022                                                           576.559306\n",
      "May_2023                                                           408.524753\n",
      "Jun_2022                                                           836.449632\n",
      "Jun_2023                                                           121.880105\n",
      "Jul_2022                                                          1631.211759\n",
      "Jul_2023                                                                  0.0\n",
      "Aug_2022                                                           444.484339\n",
      "Aug_2023                                                             5.635733\n",
      "Sep_2022                                                           100.248721\n",
      "Sep_2023                                                           216.398902\n",
      "Oct_2022                                                           444.776595\n",
      "Oct_2023                                                            90.048965\n",
      "Nov_2022                                                          1102.426915\n",
      "Nov_2023                                                           285.538308\n",
      "Dec_2022                                                          1135.753633\n",
      "Dec_2023                                                           243.159544\n",
      "forecast_index                                                       0.254711\n",
      "cost_valor                                                           1.763554\n",
      "proporcio_vendes_stock                                               0.002066\n",
      "Name: 308, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.iloc[241])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "distances = scaler.fit_transform([[i] for i in distances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [1-d[0] for d in distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m(autoencoder_index \u001b[38;5;241m=\u001b[39m distances)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "data = data.assign(autoencoder_index = distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>unitats_2022</th>\n",
       "      <th>vendes_2022</th>\n",
       "      <th>preu_venda_unitari_2022</th>\n",
       "      <th>unitats_2023</th>\n",
       "      <th>vendes_2023</th>\n",
       "      <th>preu_venda_unitari_2023</th>\n",
       "      <th>variacio_preu_venda_unitari_2022_2023</th>\n",
       "      <th>proporcio_variacio_preu_venda_unitari_2022_2023</th>\n",
       "      <th>data_darrera_entrada</th>\n",
       "      <th>...</th>\n",
       "      <th>Oct_2022</th>\n",
       "      <th>Oct_2023</th>\n",
       "      <th>Nov_2022</th>\n",
       "      <th>Nov_2023</th>\n",
       "      <th>Dec_2022</th>\n",
       "      <th>Dec_2023</th>\n",
       "      <th>forecast_index</th>\n",
       "      <th>cost_valor</th>\n",
       "      <th>proporcio_vendes_stock</th>\n",
       "      <th>autoencoder_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114230822</td>\n",
       "      <td>1018500.0</td>\n",
       "      <td>54892.49</td>\n",
       "      <td>0.053895</td>\n",
       "      <td>885500.0</td>\n",
       "      <td>58951.87</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.235256</td>\n",
       "      <td>1970-01-01 01:00:45.351</td>\n",
       "      <td>...</td>\n",
       "      <td>3532.453821</td>\n",
       "      <td>2393.860683</td>\n",
       "      <td>10290.288749</td>\n",
       "      <td>3573.065705</td>\n",
       "      <td>7437.975827</td>\n",
       "      <td>4715.931899</td>\n",
       "      <td>0.210499</td>\n",
       "      <td>1.930786</td>\n",
       "      <td>0.886494</td>\n",
       "      <td>0.508620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115030252</td>\n",
       "      <td>75900.0</td>\n",
       "      <td>6825.62</td>\n",
       "      <td>0.089929</td>\n",
       "      <td>27600.0</td>\n",
       "      <td>2127.68</td>\n",
       "      <td>0.077090</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>-0.142771</td>\n",
       "      <td>1970-01-01 01:00:45.315</td>\n",
       "      <td>...</td>\n",
       "      <td>1047.632346</td>\n",
       "      <td>427.803972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>193.955142</td>\n",
       "      <td>287.229412</td>\n",
       "      <td>150.170606</td>\n",
       "      <td>0.480055</td>\n",
       "      <td>0.997702</td>\n",
       "      <td>0.092508</td>\n",
       "      <td>0.602062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115070602</td>\n",
       "      <td>884000.0</td>\n",
       "      <td>100307.84</td>\n",
       "      <td>0.113470</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>34522.45</td>\n",
       "      <td>0.101537</td>\n",
       "      <td>-0.011934</td>\n",
       "      <td>-0.105171</td>\n",
       "      <td>1970-01-01 01:00:45.328</td>\n",
       "      <td>...</td>\n",
       "      <td>8875.043894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13683.961246</td>\n",
       "      <td>2679.708550</td>\n",
       "      <td>17310.488615</td>\n",
       "      <td>2527.829452</td>\n",
       "      <td>0.393597</td>\n",
       "      <td>1.771301</td>\n",
       "      <td>0.345224</td>\n",
       "      <td>0.466443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115130209</td>\n",
       "      <td>23217.0</td>\n",
       "      <td>5179.48</td>\n",
       "      <td>0.223090</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>3770.68</td>\n",
       "      <td>0.241710</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.083465</td>\n",
       "      <td>1970-01-01 01:00:45.281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>397.675659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>466.076696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>152.991466</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>1.009712</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>0.478677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115170581</td>\n",
       "      <td>357000.0</td>\n",
       "      <td>26188.50</td>\n",
       "      <td>0.073357</td>\n",
       "      <td>1023000.0</td>\n",
       "      <td>74195.50</td>\n",
       "      <td>0.072527</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>-0.011311</td>\n",
       "      <td>1970-01-01 01:00:45.331</td>\n",
       "      <td>...</td>\n",
       "      <td>421.745776</td>\n",
       "      <td>20349.658190</td>\n",
       "      <td>3045.917856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>496.791704</td>\n",
       "      <td>0.137538</td>\n",
       "      <td>1.423348</td>\n",
       "      <td>1.766560</td>\n",
       "      <td>0.465215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    material  unitats_2022  vendes_2022  preu_venda_unitari_2022  \\\n",
       "0  114230822     1018500.0     54892.49                 0.053895   \n",
       "1  115030252       75900.0      6825.62                 0.089929   \n",
       "2  115070602      884000.0    100307.84                 0.113470   \n",
       "3  115130209       23217.0      5179.48                 0.223090   \n",
       "4  115170581      357000.0     26188.50                 0.073357   \n",
       "\n",
       "   unitats_2023  vendes_2023  preu_venda_unitari_2023  \\\n",
       "0      885500.0     58951.87                 0.066575   \n",
       "1       27600.0      2127.68                 0.077090   \n",
       "2      340000.0     34522.45                 0.101537   \n",
       "3       15600.0      3770.68                 0.241710   \n",
       "4     1023000.0     74195.50                 0.072527   \n",
       "\n",
       "   variacio_preu_venda_unitari_2022_2023  \\\n",
       "0                               0.012679   \n",
       "1                              -0.012839   \n",
       "2                              -0.011934   \n",
       "3                               0.018620   \n",
       "4                              -0.000830   \n",
       "\n",
       "   proporcio_variacio_preu_venda_unitari_2022_2023    data_darrera_entrada  \\\n",
       "0                                         0.235256 1970-01-01 01:00:45.351   \n",
       "1                                        -0.142771 1970-01-01 01:00:45.315   \n",
       "2                                        -0.105171 1970-01-01 01:00:45.328   \n",
       "3                                         0.083465 1970-01-01 01:00:45.281   \n",
       "4                                        -0.011311 1970-01-01 01:00:45.331   \n",
       "\n",
       "   ...     Oct_2022      Oct_2023      Nov_2022     Nov_2023      Dec_2022  \\\n",
       "0  ...  3532.453821   2393.860683  10290.288749  3573.065705   7437.975827   \n",
       "1  ...  1047.632346    427.803972      0.000000   193.955142    287.229412   \n",
       "2  ...  8875.043894      0.000000  13683.961246  2679.708550  17310.488615   \n",
       "3  ...     0.000000    397.675659      0.000000   466.076696      0.000000   \n",
       "4  ...   421.745776  20349.658190   3045.917856     0.000000      0.000000   \n",
       "\n",
       "      Dec_2023  forecast_index  cost_valor  proporcio_vendes_stock  \\\n",
       "0  4715.931899        0.210499    1.930786                0.886494   \n",
       "1   150.170606        0.480055    0.997702                0.092508   \n",
       "2  2527.829452        0.393597    1.771301                0.345224   \n",
       "3   152.991466        0.230800    1.009712                0.392779   \n",
       "4   496.791704        0.137538    1.423348                1.766560   \n",
       "\n",
       "   autoencoder_index  \n",
       "0           0.508620  \n",
       "1           0.602062  \n",
       "2           0.466443  \n",
       "3           0.478677  \n",
       "4           0.465215  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data = data.drop([\"Unnamed: 0.2\", \"Unnamed: 0.1\", \"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"C:/Users/Usuario/Documents/Projectes/ChallengeAuditoria/challenge-auditoria/data/inventory_data_autoencoder.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
