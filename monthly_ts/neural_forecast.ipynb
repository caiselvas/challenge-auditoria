{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install neuralforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'material', 'unitats_2022', 'vendes_2022',\n",
      "       'preu_venda_unitari_2022', 'unitats_2023', 'vendes_2023',\n",
      "       'preu_venda_unitari_2023', 'variacio_preu_venda_unitari_2022_2023',\n",
      "       'proporcio_variacio_preu_venda_unitari_2022_2023',\n",
      "       'data_darrera_entrada', 'dies_ultima_entrada', 'data_darrera_sortida',\n",
      "       'dies_ultima_sortida', 'diferencia_entrada_sortida', 'stock_final_2023',\n",
      "       'valor_total_stock_2023', 'cost_unitari_stock_2023', 'Jan_2022',\n",
      "       'Jan_2023', 'Feb_2022', 'Feb_2023', 'Mar_2022', 'Mar_2023', 'Apr_2022',\n",
      "       'Apr_2023', 'May_2022', 'May_2023', 'Jun_2022', 'Jun_2023', 'Jul_2022',\n",
      "       'Jul_2023', 'Aug_2022', 'Aug_2023', 'Sep_2022', 'Sep_2023', 'Oct_2022',\n",
      "       'Oct_2023', 'Nov_2022', 'Nov_2023', 'Dec_2022', 'Dec_2023'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_25868\\649198885.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  data.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"C:/Users/Usuario/Documents/Projectes/ChallengeAuditoria/challenge-auditoria/data/inventory_data_month.xlsx\")\n",
    "\n",
    "\n",
    "ts = ['Jan_2022', \"Feb_2022\", \"Mar_2022\", \"Apr_2022\", \"May_2022\", \"Jun_2022\", \"Jul_2022\", \"Aug_2022\", \"Sep_2022\", \"Oct_2022\", \"Nov_2022\", \"Dec_2022\", 'Jan_2023', \"Feb_2023\", \"Mar_2023\", \"Apr_2023\", \"May_2023\", \"Jun_2023\", \"Jul_2023\", \"Aug_2023\", \"Sep_2023\", \"Oct_2023\", \"Nov_2023\", \"Dec_2023\"]\n",
    "data.fillna(0, inplace=True)\n",
    "print(data.columns)\n",
    "ts.extend([\"material\", \"vendes_2022\", \"vendes_2023\"])\n",
    "data = data[ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      unique_id  vendes_2022  vendes_2023         ds             y\n",
      "0     114230822     54892.49     58951.87 2022-01-01   4876.443011\n",
      "1     115030252      6825.62      2127.68 2022-01-01      0.000000\n",
      "2     115070602    100307.84     34522.45 2022-01-01   6065.864778\n",
      "3     115130209      5179.48      3770.68 2022-01-01    505.955967\n",
      "4     115170581     26188.50     74195.50 2022-01-01    859.708957\n",
      "...         ...          ...          ...        ...           ...\n",
      "9187  182080257     27030.19     17886.40 2023-12-01   1644.182569\n",
      "9188  182080258      3945.01         0.00 2023-12-01      0.000000\n",
      "9189  182080259    112860.80    326272.67 2023-12-01  13822.378008\n",
      "9190  182080260      8513.28     11016.96 2023-12-01      0.000000\n",
      "9191  182130161    457202.60    390388.11 2023-12-01  30437.723719\n",
      "\n",
      "[9192 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Unpivot the DataFrame\n",
    "df = df.melt(id_vars=[\"material\", \"vendes_2022\", \"vendes_2023\"], var_name='ds', value_name='y')\n",
    "\n",
    "# Extract year and month from 'ds' column\n",
    "df['ds'] = pd.to_datetime(df['ds'], format='%b_%Y')\n",
    "\n",
    "# Rename the 'material' column to 'unique_id'\n",
    "df.rename(columns={'material': 'unique_id'}, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "Seed set to 1\n",
      "Seed set to 1\n",
      "Seed set to 1\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "600       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.690     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|▊         | 1/12 [00:00<00:07,  1.45it/s, v_num=10, train_loss_step=1.93e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 1/12 [00:00<00:01,  8.55it/s, v_num=10, train_loss_step=1.2e+4, train_loss_epoch=1.08e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 31. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:00<00:01,  7.59it/s, v_num=10, train_loss_step=1.47e+4, train_loss_epoch=1.08e+4] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:00<00:01,  7.53it/s, v_num=10, train_loss_step=1.47e+4, train_loss_epoch=1.08e+4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type          | Params\n",
      "-------------------------------------------------\n",
      "0 | loss           | MAE           | 0     \n",
      "1 | padder_train   | ConstantPad1d | 0     \n",
      "2 | scaler         | TemporalNorm  | 0     \n",
      "3 | model          | ModuleList    | 4.7 M \n",
      "4 | enc_embedding  | DataEmbedding | 192   \n",
      "5 | layer_norm     | LayerNorm     | 128   \n",
      "6 | predict_linear | Linear        | 312   \n",
      "7 | projection     | Linear        | 65    \n",
      "-------------------------------------------------\n",
      "4.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.752    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:  33%|███▎      | 4/12 [00:07<00:14,  0.57it/s, v_num=11, train_loss_step=17.80, train_loss_epoch=16.00]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:07<00:14,  0.57it/s, v_num=11, train_loss_step=17.80, train_loss_epoch=16.00]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | loss          | MAE           | 0     \n",
      "1 | padder_train  | ConstantPad1d | 0     \n",
      "2 | scaler        | TemporalNorm  | 0     \n",
      "3 | decomp        | SeriesDecomp  | 0     \n",
      "4 | enc_embedding | DataEmbedding | 384   \n",
      "5 | dec_embedding | DataEmbedding | 384   \n",
      "6 | encoder       | Encoder       | 161 K \n",
      "7 | decoder       | Decoder       | 177 K \n",
      "------------------------------------------------\n",
      "339 K     Trainable params\n",
      "0         Non-trainable params\n",
      "339 K     Total params\n",
      "1.359     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:  33%|███▎      | 4/12 [00:04<00:09,  0.87it/s, v_num=12, train_loss_step=9.12e+3, train_loss_epoch=8.39e+3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:04<00:09,  0.87it/s, v_num=12, train_loss_step=9.12e+3, train_loss_epoch=8.39e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\utilsforecast\\processing.py:362: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\utilsforecast\\processing.py:414: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\neuralforecast\\tsdataset.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.temporal = torch.tensor(temporal, dtype=torch.float)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 125.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:04<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 23.80it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\neuralforecast\\core.py:184: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM, NHITS, RNN, NBEATS, TimesNet, FEDformer\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models = [NBEATS(input_size=12, h=12, max_steps=100, hist_exog_list = [\"vendes_2022\", \"vendes_2023\"]),\n",
    "              TimesNet(input_size=12, h=12, max_steps=100),\n",
    "              FEDformer(input_size=12, h=12, max_steps=100)\n",
    "              ],\n",
    "    freq = 'M'\n",
    ")\n",
    "\n",
    "nf.fit(df=df)\n",
    "new_df = nf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>NBEATS</th>\n",
       "      <th>TimesNet</th>\n",
       "      <th>FEDformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>3633.244385</td>\n",
       "      <td>4317.026855</td>\n",
       "      <td>4646.636230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>3702.182129</td>\n",
       "      <td>4136.087891</td>\n",
       "      <td>4649.607910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>3970.479248</td>\n",
       "      <td>3846.902344</td>\n",
       "      <td>4652.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>4522.752930</td>\n",
       "      <td>4480.974121</td>\n",
       "      <td>4655.167480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>4360.987305</td>\n",
       "      <td>3594.966309</td>\n",
       "      <td>4658.112305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds       NBEATS     TimesNet    FEDformer\n",
       "unique_id                                                  \n",
       "114230822 2023-12-31  3633.244385  4317.026855  4646.636230\n",
       "114230822 2024-01-31  3702.182129  4136.087891  4649.607910\n",
       "114230822 2024-02-29  3970.479248  3846.902344  4652.488281\n",
       "114230822 2024-03-31  4522.752930  4480.974121  4655.167480\n",
       "114230822 2024-04-30  4360.987305  3594.966309  4658.112305"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unique_id      Dec_2023      Jan_2024      Feb_2024      Mar_2024  \\\n",
      "0    114230822   4317.026855   4136.087891   3846.902344   4480.974121   \n",
      "1    115030252    141.553345    141.578888    183.549026    173.906799   \n",
      "2    115070602   2150.878906   2160.991943   2329.116455   2347.580566   \n",
      "3    115130209    262.094116    174.616577    292.652283    289.355011   \n",
      "4    115170581   4915.030273   4434.943848   6029.007812   4628.212891   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "378  182080257   1203.366699   1141.923340   1270.328003   1361.576416   \n",
      "379  182080258      0.542615      0.415263      0.503743      0.907837   \n",
      "380  182080259  24570.617188  20779.468750  24634.878906  24696.648438   \n",
      "381  182080260    670.174438    -40.097412    195.522522    603.965332   \n",
      "382  182130161  28616.023438  23385.347656  29289.705078  33768.546875   \n",
      "\n",
      "         Apr_2024      May_2024      Jun_2024      Jul_2024      Aug_2024  \\\n",
      "0     3594.966309   3789.168701   4053.077393   3851.866699   3785.044434   \n",
      "1      151.231995    166.034210    159.206406    126.840851    130.721069   \n",
      "2     2051.029541   2324.423584   2562.206543   2709.159668   2539.240967   \n",
      "3      255.081604    275.868958    241.519623    216.088287    257.371155   \n",
      "4     4175.877441   4975.629883   4121.580566   4765.595215   2776.268555   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "378   1254.836548   1290.559570   1269.251465   1154.664795   1311.285278   \n",
      "379      0.641635      0.737570      0.847199      0.763617      0.605765   \n",
      "380  26879.757812  24686.396484  26434.277344  20434.597656  19838.441406   \n",
      "381    301.707581    317.303711    200.134827     34.301208     10.444824   \n",
      "382  27881.218750  28632.679688  26863.484375  24145.662109  23303.339844   \n",
      "\n",
      "         Sep_2024      Oct_2024      Nov_2024  \n",
      "0     4022.243164   3097.625000   4181.822266  \n",
      "1      217.617554    184.155548    244.059616  \n",
      "2     2061.626953   2496.264404   2898.566406  \n",
      "3      234.045242    196.524918    271.258728  \n",
      "4     4756.837891   4247.753906   4918.934082  \n",
      "..            ...           ...           ...  \n",
      "378   1174.821167   1333.019043   1745.010742  \n",
      "379      0.615288      0.431203      1.144540  \n",
      "380  26319.679688  18428.130859  28381.259766  \n",
      "381    305.138733    492.461334    744.405640  \n",
      "382  29465.589844  20825.382812  28129.978516  \n",
      "\n",
      "[383 rows x 13 columns]\n",
      "     unique_id      Dec_2023      Jan_2024      Feb_2024      Mar_2024  \\\n",
      "0    114230822   3633.244385   3702.182129   3970.479248   4522.752930   \n",
      "1    115030252    241.708588    153.883667    128.897125    223.399521   \n",
      "2    115070602   2429.710205   2663.228027   2212.334229   2456.969238   \n",
      "3    115130209    186.998856    186.759201    189.941040    137.806213   \n",
      "4    115170581   6678.361328   5253.115723   7045.935547   4255.138184   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "378  182080257   1213.146973   1272.343872   1107.849609    968.502869   \n",
      "379  182080258      0.510572      0.439281      0.414640      0.494350   \n",
      "380  182080259  22909.841797  19510.150391  14872.630859  25970.746094   \n",
      "381  182080260    308.198792    516.171265    208.395172    204.455322   \n",
      "382  182130161  27835.687500  22420.244141  26057.037109  36698.496094   \n",
      "\n",
      "         Apr_2024      May_2024      Jun_2024      Jul_2024      Aug_2024  \\\n",
      "0     4360.987305   3077.870361   3213.406006   3776.976807   4436.406738   \n",
      "1      176.548340    172.323807    154.656784    132.143280    209.203552   \n",
      "2     2155.907227   2230.344971   2541.157959   2325.636963   2308.203125   \n",
      "3      177.258911    218.112366    184.047455    164.246033    135.042969   \n",
      "4     4518.164062   8160.791016   5555.985352   5171.462891   4780.285645   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "378   1268.785400   1237.690674   1198.700928   1125.531372    899.665894   \n",
      "379      0.400286      0.391339      0.254845      0.384955      0.383103   \n",
      "380  22769.802734  17301.513672  15211.856445  14293.544922  19765.966797   \n",
      "381    489.654907    292.496399    435.227112    408.342438    484.078613   \n",
      "382  27916.222656  19773.062500  24837.705078  20530.248047  25110.095703   \n",
      "\n",
      "         Sep_2024      Oct_2024      Nov_2024  \n",
      "0     4337.048340   2827.324951   3253.842041  \n",
      "1      166.123596    112.116623     84.135178  \n",
      "2     2367.226318   2247.826660   2065.668457  \n",
      "3      159.603622    162.004257    107.821037  \n",
      "4     4811.689941   5087.026855   3353.307129  \n",
      "..            ...           ...           ...  \n",
      "378   1171.766235   1078.107422   1041.217651  \n",
      "379      0.247349      0.316379      0.445831  \n",
      "380  18254.855469  11912.604492   6592.174805  \n",
      "381    685.808655      0.974419     -3.580376  \n",
      "382  29456.648438  21357.392578  17790.964844  \n",
      "\n",
      "[383 rows x 13 columns]\n",
      "     unique_id      Dec_2023      Jan_2024      Feb_2024      Mar_2024  \\\n",
      "0    114230822   4646.636230   4649.607910   4652.488281   4655.167480   \n",
      "1    115030252    149.458008    149.127350    148.935654    149.178818   \n",
      "2    115070602   2412.935791   2417.139648   2421.477539   2426.010986   \n",
      "3    115130209    223.264008    227.211960    231.269684    235.395432   \n",
      "4    115170581   4233.840332   4338.026367   4442.422852   4546.913086   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "378  182080257   1120.746094   1136.719971   1152.716919   1168.848633   \n",
      "379  182080258      0.077809      0.029470      0.027510      0.017123   \n",
      "380  182080259  21482.437500  21706.951172  21931.601562  22156.332031   \n",
      "381  182080260    730.950378    738.737366    746.339294    753.404968   \n",
      "382  182130161  25730.300781  25998.873047  26267.460938  26536.146484   \n",
      "\n",
      "         Apr_2024      May_2024      Jun_2024      Jul_2024      Aug_2024  \\\n",
      "0     4658.112305   4661.187500   4664.159668   4699.001465   4578.864258   \n",
      "1      149.328552    149.097015    148.891235    137.368530    150.435638   \n",
      "2     2430.218506   2434.384521   2438.608398   2429.827148   2439.518311   \n",
      "3      239.478073    243.588837    247.742447    243.958755    229.051041   \n",
      "4     4651.338867   4755.837402   4860.296387   4975.077148   4951.539551   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "378   1184.922485   1201.111572   1217.571045   1179.351929   1212.991333   \n",
      "379      0.012579      0.026358      0.044980      0.015580     -0.004931   \n",
      "380  22381.082031  22605.851562  22830.746094  21586.951172  21240.466797   \n",
      "381    760.587158    768.106384    775.594971    817.147339    781.828491   \n",
      "382  26804.767578  27073.429688  27342.232422  26858.855469  26882.722656   \n",
      "\n",
      "         Sep_2024      Oct_2024      Nov_2024  \n",
      "0     4706.655273   4697.592285   4933.445801  \n",
      "1      133.680923    146.163071    116.238068  \n",
      "2     2560.968018   2663.215088   2927.561768  \n",
      "3      215.103363    208.607819    301.068787  \n",
      "4     4428.520020   4767.413574   5625.773926  \n",
      "..            ...           ...           ...  \n",
      "378   1148.997681   1235.895996   1344.065918  \n",
      "379     -0.010795      0.052982      0.009107  \n",
      "380  19624.013672  19477.103516  21926.480469  \n",
      "381    832.886841    839.476929   1051.895264  \n",
      "382  25897.369141  26539.230469  30210.230469  \n",
      "\n",
      "[383 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "def save_result(new_df, name):\n",
    "    df = pd.DataFrame(new_df)\n",
    "\n",
    "    # Convert 'ds' column to datetime\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    df_pivot = df.pivot_table(index='unique_id', columns='ds', values=f'{name}', aggfunc='first')\n",
    "\n",
    "    # Reset index to make 'unique_id' a column again\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "\n",
    "    # Rename columns\n",
    "    df_pivot.columns.name = None  # Remove the name of the columns index\n",
    "    df_pivot.columns = ['unique_id'] + [col.strftime('%b_%Y') for col in df_pivot.columns[1:]]\n",
    "\n",
    "    print(df_pivot)\n",
    "\n",
    "    df_pivot = df_pivot.drop([\"Dec_2023\"], axis=1)\n",
    "    forecasts = df_pivot.set_index('unique_id').T.to_dict(orient='list')\n",
    "    import json\n",
    "    new_forecasts = {key: list(value) for key, value in forecasts.items()}\n",
    "    # Saving the dictionary to a JSON file\n",
    "    with open(f\"../forecast/{name}.json\", \"w\") as json_file:\n",
    "        json.dump(new_forecasts, json_file)\n",
    "\n",
    "save_result(new_df, 'TimesNet')\n",
    "save_result(new_df, 'NBEATS')\n",
    "save_result(new_df, 'FEDformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preentrenat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No furula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.models import LSTM, NHITS, RNN, NBEATS\n",
    "\n",
    "nf2 = NBEATS.load_from_checkpoint(checkpoint_path='./nbeats_m4.ckpt',h=12,input_size=12)\n",
    "Y_hat_df = nf2.predict().reset_index()\n",
    "Y_hat_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
