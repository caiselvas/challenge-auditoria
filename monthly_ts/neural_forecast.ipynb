{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install neuralforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'material', 'unitats_2022', 'vendes_2022',\n",
      "       'preu_venda_unitari_2022', 'unitats_2023', 'vendes_2023',\n",
      "       'preu_venda_unitari_2023', 'variacio_preu_venda_unitari_2022_2023',\n",
      "       'proporcio_variacio_preu_venda_unitari_2022_2023',\n",
      "       'data_darrera_entrada', 'dies_ultima_entrada', 'data_darrera_sortida',\n",
      "       'dies_ultima_sortida', 'diferencia_entrada_sortida', 'stock_final_2023',\n",
      "       'valor_total_stock_2023', 'cost_unitari_stock_2023', 'Jan_2022',\n",
      "       'Jan_2023', 'Feb_2022', 'Feb_2023', 'Mar_2022', 'Mar_2023', 'Apr_2022',\n",
      "       'Apr_2023', 'May_2022', 'May_2023', 'Jun_2022', 'Jun_2023', 'Jul_2022',\n",
      "       'Jul_2023', 'Aug_2022', 'Aug_2023', 'Sep_2022', 'Sep_2023', 'Oct_2022',\n",
      "       'Oct_2023', 'Nov_2022', 'Nov_2023', 'Dec_2022', 'Dec_2023'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_25868\\649198885.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  data.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"C:/Users/Usuario/Documents/Projectes/ChallengeAuditoria/challenge-auditoria/data/inventory_data_month.xlsx\")\n",
    "\n",
    "\n",
    "ts = ['Jan_2022', \"Feb_2022\", \"Mar_2022\", \"Apr_2022\", \"May_2022\", \"Jun_2022\", \"Jul_2022\", \"Aug_2022\", \"Sep_2022\", \"Oct_2022\", \"Nov_2022\", \"Dec_2022\", 'Jan_2023', \"Feb_2023\", \"Mar_2023\", \"Apr_2023\", \"May_2023\", \"Jun_2023\", \"Jul_2023\", \"Aug_2023\", \"Sep_2023\", \"Oct_2023\", \"Nov_2023\", \"Dec_2023\"]\n",
    "data.fillna(0, inplace=True)\n",
    "print(data.columns)\n",
    "ts.extend([\"material\", \"vendes_2022\", \"vendes_2023\"])\n",
    "data = data[ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      unique_id  vendes_2022  vendes_2023         ds             y\n",
      "0     114230822     54892.49     58951.87 2022-01-01   1002.876978\n",
      "1     115030252      6825.62      2127.68 2022-01-01     56.596995\n",
      "2     115070602    100307.84     34522.45 2022-01-01   6079.577671\n",
      "3     115130209      5179.48      3770.68 2022-01-01    259.045453\n",
      "4     115170581     26188.50     74195.50 2022-01-01   1180.711925\n",
      "...         ...          ...          ...        ...           ...\n",
      "9187  182080257     27030.19     17886.40 2023-12-01   1257.852506\n",
      "9188  182080258      3945.01         0.00 2023-12-01      0.000000\n",
      "9189  182080259    112860.80    326272.67 2023-12-01  26980.031073\n",
      "9190  182080260      8513.28     11016.96 2023-12-01      0.000000\n",
      "9191  182130161    457202.60    390388.11 2023-12-01  43500.579629\n",
      "\n",
      "[9192 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Unpivot the DataFrame\n",
    "df = df.melt(id_vars=[\"material\", \"vendes_2022\", \"vendes_2023\"], var_name='ds', value_name='y')\n",
    "\n",
    "# Extract year and month from 'ds' column\n",
    "df['ds'] = pd.to_datetime(df['ds'], format='%b_%Y')\n",
    "\n",
    "# Rename the 'material' column to 'unique_id'\n",
    "df.rename(columns={'material': 'unique_id'}, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "Seed set to 1\n",
      "Seed set to 1\n",
      "Seed set to 1\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 2.4 M \n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "600       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.690     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:00<00:01,  7.06it/s, v_num=16, train_loss_step=7.64e+3, train_loss_epoch=7.05e+3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:00<00:01,  6.99it/s, v_num=16, train_loss_step=7.64e+3, train_loss_epoch=7.05e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type          | Params\n",
      "-------------------------------------------------\n",
      "0 | loss           | MAE           | 0     \n",
      "1 | padder_train   | ConstantPad1d | 0     \n",
      "2 | scaler         | TemporalNorm  | 0     \n",
      "3 | model          | ModuleList    | 4.7 M \n",
      "4 | enc_embedding  | DataEmbedding | 192   \n",
      "5 | layer_norm     | LayerNorm     | 128   \n",
      "6 | predict_linear | Linear        | 312   \n",
      "7 | projection     | Linear        | 65    \n",
      "-------------------------------------------------\n",
      "4.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.752    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:  33%|███▎      | 4/12 [00:05<00:11,  0.67it/s, v_num=17, train_loss_step=18.10, train_loss_epoch=230.0]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:05<00:11,  0.67it/s, v_num=17, train_loss_step=18.10, train_loss_epoch=230.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | loss          | MAE           | 0     \n",
      "1 | padder_train  | ConstantPad1d | 0     \n",
      "2 | scaler        | TemporalNorm  | 0     \n",
      "3 | decomp        | SeriesDecomp  | 0     \n",
      "4 | enc_embedding | DataEmbedding | 384   \n",
      "5 | dec_embedding | DataEmbedding | 384   \n",
      "6 | encoder       | Encoder       | 161 K \n",
      "7 | decoder       | Decoder       | 177 K \n",
      "------------------------------------------------\n",
      "339 K     Trainable params\n",
      "0         Non-trainable params\n",
      "339 K     Total params\n",
      "1.359     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:  33%|███▎      | 4/12 [00:04<00:08,  0.98it/s, v_num=18, train_loss_step=7.45e+3, train_loss_epoch=5.99e+3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  33%|███▎      | 4/12 [00:04<00:08,  0.97it/s, v_num=18, train_loss_step=7.45e+3, train_loss_epoch=5.99e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\utilsforecast\\processing.py:362: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\utilsforecast\\processing.py:414: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\neuralforecast\\tsdataset.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.temporal = torch.tensor(temporal, dtype=torch.float)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 103.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:04<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 12/12 [00:00<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Documents\\Projectes\\ChallengeAuditoria\\challenge-auditoria\\.venv\\Lib\\site-packages\\neuralforecast\\core.py:184: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM, NHITS, RNN, NBEATS, TimesNet, FEDformer\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models = [NBEATS(input_size=12, h=12, max_steps=100, hist_exog_list = [\"vendes_2022\", \"vendes_2023\"]),\n",
    "              TimesNet(input_size=12, h=12, max_steps=100),\n",
    "              FEDformer(input_size=12, h=12, max_steps=100)\n",
    "              ],\n",
    "    freq = 'M'\n",
    ")\n",
    "\n",
    "nf.fit(df=df)\n",
    "new_df = nf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>NBEATS</th>\n",
       "      <th>TimesNet</th>\n",
       "      <th>FEDformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>5754.993164</td>\n",
       "      <td>5683.444824</td>\n",
       "      <td>4468.245117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>5427.899414</td>\n",
       "      <td>6718.735352</td>\n",
       "      <td>4453.424805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>4789.617188</td>\n",
       "      <td>6198.358398</td>\n",
       "      <td>4438.791016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>6387.427246</td>\n",
       "      <td>8089.680176</td>\n",
       "      <td>4424.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114230822</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>5989.224121</td>\n",
       "      <td>5609.387207</td>\n",
       "      <td>4409.607422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds       NBEATS     TimesNet    FEDformer\n",
       "unique_id                                                  \n",
       "114230822 2023-12-31  5754.993164  5683.444824  4468.245117\n",
       "114230822 2024-01-31  5427.899414  6718.735352  4453.424805\n",
       "114230822 2024-02-29  4789.617188  6198.358398  4438.791016\n",
       "114230822 2024-03-31  6387.427246  8089.680176  4424.273438\n",
       "114230822 2024-04-30  5989.224121  5609.387207  4409.607422"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     unique_id      Dec_2023      Jan_2024      Feb_2024      Mar_2024  \\\n",
      "0    114230822   5683.444824   6718.735352   6198.358398   8089.680176   \n",
      "1    115030252     29.447693     82.648346     19.445480     28.154022   \n",
      "2    115070602     14.385742    190.172852    204.369141   -733.944336   \n",
      "3    115130209     55.557281     96.026947     57.048645     23.273682   \n",
      "4    115170581   6594.920898   8530.551758   6857.986328   8251.452148   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "378  182080257   1633.328857   1715.333374   1789.099365   1589.961304   \n",
      "379  182080258    -11.405964     -7.583454      0.028225    -30.679569   \n",
      "380  182080259  27359.343750  28440.375000  26196.181641  29659.181641   \n",
      "381  182080260    393.740479    442.560211    379.795410    -61.202576   \n",
      "382  182130161  40730.632812  43166.953125  45495.390625  49292.257812   \n",
      "\n",
      "         Apr_2024      May_2024      Jun_2024      Jul_2024      Aug_2024  \\\n",
      "0     5609.387207   5998.307617   5534.715820   5640.313477   4928.455078   \n",
      "1       45.043121    -27.553696      1.013580     71.421997    -17.535019   \n",
      "2      133.664307   -783.133789    299.504150    536.363281   -440.066895   \n",
      "3        6.846405    -11.001526     34.530823     82.227982     71.367996   \n",
      "4     7167.856934   7548.204102   7755.114258   7713.915039   6395.775879   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "378   1751.023193   1771.888672   1894.284668   1553.361694   1680.319336   \n",
      "379    -34.159252    -24.994602    -15.163719     -1.681183    -12.762913   \n",
      "380  27365.601562  28974.699219  28417.201172  24740.244141  26901.955078   \n",
      "381    389.256958    204.088806    105.838623    252.992371    330.728027   \n",
      "382  43273.546875  51679.957031  53968.292969  58508.734375  44455.214844   \n",
      "\n",
      "         Sep_2024      Oct_2024      Nov_2024  \n",
      "0     5488.125977   4745.267578   3714.589355  \n",
      "1       -4.869186     77.772949     86.811974  \n",
      "2      -67.565674    876.300049   1001.791260  \n",
      "3       -3.565216    143.199051    160.928802  \n",
      "4     5846.104492   6097.291504   5530.518066  \n",
      "..            ...           ...           ...  \n",
      "378   1665.671143   1588.989014   1829.161377  \n",
      "379      5.567471     29.355091     44.501411  \n",
      "380  24905.822266  20271.824219  22009.593750  \n",
      "381     92.080444    298.609558    320.183411  \n",
      "382  48422.250000  46633.562500  57897.304688  \n",
      "\n",
      "[383 rows x 13 columns]\n",
      "     unique_id      Dec_2023      Jan_2024      Feb_2024      Mar_2024  \\\n",
      "0    114230822   5754.993164   5427.899414   4789.617188   6387.427246   \n",
      "1    115030252     72.093689     82.320992     97.121185     98.555603   \n",
      "2    115070602   1332.129272   1355.096924   1595.439209   1441.616333   \n",
      "3    115130209    202.758255    137.880295    202.404785    158.993088   \n",
      "4    115170581   5706.722168   5497.751953   5077.123047   6995.716309   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "378  182080257   1344.813721   1261.281616   1360.078613   1213.660278   \n",
      "379  182080258      3.165432     -0.118232     -3.702289     -4.905115   \n",
      "380  182080259  27358.789062  25558.845703  25371.882812  28394.447266   \n",
      "381  182080260    270.598022    366.219269    642.164185    862.051270   \n",
      "382  182130161  34573.210938  32882.257812  34768.214844  32770.007812   \n",
      "\n",
      "         Apr_2024      May_2024      Jun_2024      Jul_2024      Aug_2024  \\\n",
      "0     5989.224121   5380.792480   6029.496582   5216.856934   4887.631836   \n",
      "1       55.678780     77.540558     99.894958    114.396309     77.518318   \n",
      "2      294.478027   1164.009033   1094.185059   1622.093018    870.652222   \n",
      "3      161.863602    121.045296    114.829338    141.190430     96.346924   \n",
      "4     5632.972656   5631.410156   6279.882812   5427.233887   5374.625977   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "378   1438.337036   1224.627075   1234.034912   1140.997070   1085.682617   \n",
      "379    -12.964386     -7.211672     -7.953176     -4.590561     -0.643284   \n",
      "380  24094.562500  26987.630859  27021.890625  26953.259766  22819.259766   \n",
      "381    894.669067    642.213501    597.841431    597.324219    402.271027   \n",
      "382  34486.812500  28353.560547  28310.906250  31567.273438  27696.136719   \n",
      "\n",
      "         Sep_2024      Oct_2024      Nov_2024  \n",
      "0     4228.521484   4689.068848   5246.577148  \n",
      "1       62.326530     74.472702    105.207520  \n",
      "2      630.884766   1215.269043   1201.305176  \n",
      "3      104.145706    128.076538    142.437500  \n",
      "4     4097.345215   5494.290039   5399.370117  \n",
      "..            ...           ...           ...  \n",
      "378   1045.775391    930.644836    884.898682  \n",
      "379    -10.611875      0.287218     -5.650517  \n",
      "380  20369.642578  20561.455078  17648.044922  \n",
      "381    392.330017    246.589966    409.942444  \n",
      "382  26191.355469  25089.943359  22795.691406  \n",
      "\n",
      "[383 rows x 13 columns]\n",
      "     unique_id      Dec_2023      Jan_2024      Feb_2024      Mar_2024  \\\n",
      "0    114230822   4468.245117   4453.424805   4438.791016   4424.273438   \n",
      "1    115030252     77.480431     79.407059     81.009140     82.958023   \n",
      "2    115070602   1627.171387   1653.364380   1679.096436   1705.109375   \n",
      "3    115130209    195.664398    195.747986    196.305603    196.479523   \n",
      "4    115170581   5048.252930   5089.468750   5130.737793   5172.241699   \n",
      "..         ...           ...           ...           ...           ...   \n",
      "378  182080257   1549.227783   1530.626587   1512.581665   1494.816406   \n",
      "379  182080258     23.936300     24.678049     25.110846     25.547707   \n",
      "380  182080259  23903.933594  24099.410156  24294.833984  24490.359375   \n",
      "381  182080260    434.478333    432.588257    430.902405    429.293610   \n",
      "382  182130161  32301.291016  31795.337891  31290.121094  30784.652344   \n",
      "\n",
      "         Apr_2024      May_2024      Jun_2024      Jul_2024      Aug_2024  \\\n",
      "0     4409.607422   4395.074219   4380.575195   4265.670410   4098.623047   \n",
      "1       84.708534     86.705040     88.728065     94.075943     96.837379   \n",
      "2     1731.079102   1757.286011   1783.459473   1836.155396   1800.025757   \n",
      "3      196.549698    196.509842    196.448471    191.768829    193.718506   \n",
      "4     5213.597656   5255.177246   5296.777832   5344.599609   5324.601562   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "378   1476.275269   1457.467651   1438.863037   1397.652588   1399.746216   \n",
      "379     25.920238     26.298330     26.617107     28.629988     31.805056   \n",
      "380  24685.906250  24881.544922  25077.210938  25016.673828  23747.759766   \n",
      "381    427.619324    426.037567    424.710999    378.868164    324.337067   \n",
      "382  30278.740234  29772.589844  29266.568359  27818.958984  27845.117188   \n",
      "\n",
      "         Sep_2024      Oct_2024      Nov_2024  \n",
      "0     3942.016602   4133.061035   5023.529297  \n",
      "1      112.649940    134.839798    203.356339  \n",
      "2     2005.094238   2267.914307   3031.065186  \n",
      "3      210.556046    236.931992    240.855469  \n",
      "4     5569.124023   5906.108398   6993.424316  \n",
      "..            ...           ...           ...  \n",
      "378   1332.052734   1273.271484   1260.859497  \n",
      "379     36.086254     39.315083     30.825027  \n",
      "380  24292.140625  23841.796875  30725.017578  \n",
      "381    337.230164    423.006226    772.604980  \n",
      "382  26775.783203  26028.695312  24320.128906  \n",
      "\n",
      "[383 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "def save_result(new_df, name):\n",
    "    df = pd.DataFrame(new_df)\n",
    "\n",
    "    # Convert 'ds' column to datetime\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    df_pivot = df.pivot_table(index='unique_id', columns='ds', values=f'{name}', aggfunc='first')\n",
    "\n",
    "    # Reset index to make 'unique_id' a column again\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "\n",
    "    # Rename columns\n",
    "    df_pivot.columns.name = None  # Remove the name of the columns index\n",
    "    df_pivot.columns = ['unique_id'] + [col.strftime('%b_%Y') for col in df_pivot.columns[1:]]\n",
    "\n",
    "    print(df_pivot)\n",
    "\n",
    "    df_pivot = df_pivot.drop([\"Dec_2023\"], axis=1)\n",
    "    forecasts = df_pivot.set_index('unique_id').T.to_dict(orient='list')\n",
    "    import json\n",
    "    new_forecasts = {key: list(value) for key, value in forecasts.items()}\n",
    "    # Saving the dictionary to a JSON file\n",
    "    with open(f\"../forecast/{name}.json\", \"w\") as json_file:\n",
    "        json.dump(new_forecasts, json_file)\n",
    "\n",
    "save_result(new_df, 'TimesNet')\n",
    "save_result(new_df, 'NBEATS')\n",
    "save_result(new_df, 'FEDformer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preentrenat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No furula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.models import LSTM, NHITS, RNN, NBEATS\n",
    "\n",
    "nf2 = NBEATS.load_from_checkpoint(checkpoint_path='./nbeats_m4.ckpt',h=12,input_size=12)\n",
    "Y_hat_df = nf2.predict().reset_index()\n",
    "Y_hat_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
